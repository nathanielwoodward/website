<!DOCTYPE html>
<html lang="en">
    
    


    <head>
    <link href="https://gmpg.org/xfn/11" rel="profile">
    <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta http-equiv="Cache-Control" content="public" />
<!-- Enable responsiveness on mobile devices -->
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">
<meta name="generator" content="Hugo 0.60.1" />

    
    
    

<title>Basic Stats U Need #3: ANOVA • Nathaniel Woodward</title>


<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Basic Stats U Need #3: ANOVA"/>
<meta name="twitter:description" content="One-Way ANOVA by way of Two-Sample T-Test Calculations Sums of Squares Plot Effect Size Assumptions Post Hoc Tests   One-Way ANOVA by way of Two-Sample T-Test If the hero of our last post was William “Student” Gosset, then the hero of this and the next few posts will be Sir Ronald Fisher. After Student had derived the t distribution, he sent it to Fisher along with an historically ironic note: “I am sending you a copy of Student’s Tables as you are the only man that’s ever likely to use them!"/>

<meta property="og:title" content="Basic Stats U Need #3: ANOVA" />
<meta property="og:description" content="One-Way ANOVA by way of Two-Sample T-Test Calculations Sums of Squares Plot Effect Size Assumptions Post Hoc Tests   One-Way ANOVA by way of Two-Sample T-Test If the hero of our last post was William “Student” Gosset, then the hero of this and the next few posts will be Sir Ronald Fisher. After Student had derived the t distribution, he sent it to Fisher along with an historically ironic note: “I am sending you a copy of Student’s Tables as you are the only man that’s ever likely to use them!" />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/basic-stats-u-need-3-anova/" />
<meta property="article:published_time" content="2017-08-27T00:00:00+00:00" />
<meta property="article:modified_time" content="2017-08-27T00:00:00+00:00" /><meta property="og:site_name" content=" " />


    


<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css">








<link rel="stylesheet" href="/scss/hyde-hyde.43109490338b28cdd7a74845262efe59bf66fdc3530f5e818a66c9a579a79080.css" integrity="sha256-QxCUkDOLKM3Xp0hFJi7&#43;Wb9m/cNTD16BimbJpXmnkIA=">


<link rel="stylesheet" href="/scss/print.8c61428a4ae8b36c028e9198876312a2de5a2b3c80bbbdcceb98d738691c4f6b.css" integrity="sha256-jGFCikros2wCjpGYh2MSot5aKzyAu73M65jXOGkcT2s=" media="print">



    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
    <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
    <!-- Icons -->
    <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/apple-touch-icon-144-precomposed.png">
    <link rel="shortcut icon" href="/favicon.png">
    
    <script type="text/javascript"
   src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<script src="//ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script>
<script type="text/javascript" src="/js/bigfoot.min.js"></script>
<script type="text/javascript">
    $.bigfoot();
</script>

</head>


    <body class="theme-base-09 ">
    
<div class="sidebar">
  <div class="container ">
    <div class="sidebar-about">
    
      
        
        
        
        
        <div class="author-image">
           <a href="/"><img src="/img/headshot_cropped_f2019.png" alt="Nathaniel Woodward" class="img--circle img--headshot element--center"></a>
        </div>
        
      
      <p class="site__description">
      <a href="mailto:nathanielraley@gmail.com"> Nathaniel Woodward 
      </a></p>
    </div>
    <div class="collapsible-menu">
      <input type="checkbox" id="menuToggle">
      <label for="menuToggle">Nathaniel Woodward</label>
      <div class="menu-content">
        <div>
	<ul class="sidebar-nav">
		 
		 
			 
				<li>
					<a href="/about/">
						<span>About</span>
					</a>
				</li>
			 
		 
			 
				<li>
					<a href="/portfolio/">
						<span>Portfolio</span>
					</a>
				</li>
			 
		 
			 
				<li>
					<a href="/teaching/">
						<span>Teaching</span>
					</a>
				</li>
			 
		 
			 
				<li>
					<a href="/resume.html">
						<span>Vitae</span>
					</a>
				</li>
			 
		
	</ul>
</div>

        <br>
        <section class="social">
	
	<a href="https://twitter.com/Distributino" rel="me"><i class="fab fa-twitter fa-lg" aria-hidden="true"></i></a>
	
	
	
	<a href="https://github.com/nathanielwoodward" rel="me"><i class="fab fa-github fa-lg" aria-hidden="true"></i></a>
	
	
	
	
	
	
	
	<a href="https://linkedin.com/in/nathanielraley" rel="me"><i class="fab fa-linkedin fa-lg" aria-hidden="true"></i></a>
	
	
	
	
	
	
	
	<a href="https://last.fm/user/ramimba" rel="me"><i class="fab fa-lastfm fa-lg" aria-hidden="true"></i></a>
	
	
	
	
	
</section>

      </div>
    </div>
    
<div class="copyright">
  &copy; 2022  
  
    <a href="https://creativecommons.org/licenses/by-sa/4.0">CC BY-SA 4.0</a>
  
</div>



  </div>
</div>

        <div class="content container">
            
    
<article>
  <header>
    <h1>Basic Stats U Need #3: ANOVA</h1>
    
    
<div class="post__meta">
    
    
      <i class="fas fa-calendar-alt"></i> Aug 27, 2017
    
    
    
    
    
    <br/>
    <i class="fas fa-clock"></i> 25 min read
</div>


  </header>
  
  
  <div class="post">
    

<div id="TOC">
<ul>
<li><a href="#one-way-anova-by-way-of-two-sample-t-test">One-Way ANOVA by way of Two-Sample T-Test</a></li>
<li><a href="#calculations">Calculations</a></li>
<li><a href="#sums-of-squares-plot">Sums of Squares Plot</a></li>
<li><a href="#effect-size">Effect Size</a></li>
<li><a href="#assumptions">Assumptions</a></li>
<li><a href="#post-hoc-tests">Post Hoc Tests</a></li>
</ul>
</div>

<div id="one-way-anova-by-way-of-two-sample-t-test" class="section level2">
<h2>One-Way ANOVA by way of Two-Sample T-Test</h2>
<p>If the hero of <a href="http://www.nathanielwoodward.com/2017/08/23/basic-stats-u-need-t-test/">our last post</a> was William “Student” Gosset, then the hero of this and the next few posts will be <a href="https://en.wikipedia.org/wiki/Ronald_Fisher">Sir Ronald Fisher</a>. After Student had derived the <em>t</em> distribution, he sent it to Fisher along with an historically ironic note: “I am sending you a copy of Student’s Tables as you are the only man that’s ever likely to use them!”</p>
<p>We have Fisher to thank for the Analysis of Variance (ANOVA), a technique which generalizes the independent two-sample <em>t</em>-test to more than two groups (we also have him to thank for the term “variance” itself). Echoing remarks I made in the first post of this series, ANOVA is a superb teaching/learning tool for students of inferential statistics (despite being easily subsumed by the linear model framework). There are tons of blog posts about ANOVA, but I want to walk you through <em>the way I was taught</em> this concept because I thought it was extremely effective.<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a> Let’s set the stage with a simple example first, with which we will illustate the computations required for conducting a one-way ANOVA.</p>
<p>Let’s say you have developed 4 different fertilizers and you want to test whether they affect plant growth differently. You have at your disposal 20 genetically identical plants, so you randomly assign each plant to one of the four fertilizer conditions. You do this because there could still be initial differences among the plants (maybe some were sprouted on the edge of the container vs the middle, etc) and randomization spreads any systematic differences out across fertilizer conditions, so that the conditions are as similar in composition as possible before they receive the treatment. Besides the fertilizer treatment, everything else about the four conditions should be held constant (amount of water, sun, etc.) so that the only variable that could plausibly account for differential plant growth is the treatment itself. Thus 5 random plants get fertilizer A, 5 get B, 5 get C, and 5 get D. After growing the plants for a fixed period of time, we collect the outcome data. Let’s measure each plant’s height in centimeters (though yield might be more appropriate). These heights are given below</p>
<center>
<table>
<thead>
<tr class="header">
<th align="center">A</th>
<th align="center">B</th>
<th align="center">C</th>
<th align="center">D</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">6</td>
<td align="center">9</td>
<td align="center">4</td>
<td align="center">7</td>
</tr>
<tr class="even">
<td align="center">7</td>
<td align="center">10</td>
<td align="center">6</td>
<td align="center">9</td>
</tr>
<tr class="odd">
<td align="center">8</td>
<td align="center">12</td>
<td align="center">6</td>
<td align="center">10</td>
</tr>
<tr class="even">
<td align="center">9</td>
<td align="center">14</td>
<td align="center">6</td>
<td align="center">11</td>
</tr>
<tr class="odd">
<td align="center">10</td>
<td align="center">15</td>
<td align="center">8</td>
<td align="center">13</td>
</tr>
</tbody>
</table>
</center>
<p>OK then, so we want to test whether there is any difference in plant height among fertilizer groups. If we just had two groups, we could use a two-sample t-test. Considering only A and C for example (and assuming equal variances), we know that</p>
<p><span class="math display">\[
t=\frac{\bar{X}_A-\bar{X}_C}{\sqrt{s_p^2 \left(\frac{1}{n_A}+\frac{1}{n_C}\right)}} \text{      ,}
\\
\begin{align}
\\
s_p^2&amp;=\frac{(n_A-1)s_A^2 + (n_B-1)s_B^2}{n_A+n_B-2}\\
\\
 &amp;= \frac{\sum_{i=1}^{n_A}(X_i-\bar{X}_A)^2 + \sum_{j=1}^{n_B}(X_j-\bar{X}_B)^2}{n_A+n_B-2}\\
\end{align}
\]</span>
Since <span class="math inline">\(n_A = n_B = n\)</span>, this reduces to</p>
<p><span class="math display">\[
t=\frac{\bar{X}_A-\bar{X}_C}{\sqrt{s_p^2 \left(\frac{2}{n}\right)}} \text{      ,}
\\
\begin{align}
\\
s_p^2&amp;=\frac{(s_A^2+s_B^2)}{2}\\
\\
 &amp;= \frac{\frac{\sum_{i=1}^{n}(X_i-\bar{X}_A)^2}{n-1}+\frac{\sum_{j=1}^{n}(X_j-\bar{X}_B)^2}{n-1}}{2}=\frac{\sum_{i=1}^{n}(X_i-\bar{X}_A)^2 + \sum_{j=1}^{n}(X_j-\bar{X}_B)^2}{2(n-1)}\\
\end{align}
\]</span></p>
<p>Using our data for A and C, let’s calculate <span class="math inline">\(t\)</span> using this last formula for <span class="math inline">\(s_p\)</span> (it looks more complicated, but trust me on this).</p>
<pre class="r"><code>heights&lt;-data.frame(A=c(6,7,8,9,10), B=c(9, 10, 12, 14, 15), C=c(4,6,6,6,8), D=c(7,9,10,11,13))
n=5
meanA&lt;-mean(heights$A); meanA
## [1] 8
meanC&lt;-mean(heights$C); meanC
## [1] 6
# What is the difference between the mean of group A and the mean of group C?
meanDiff&lt;-meanA-meanC; meanDiff
## [1] 2
# Now we subtract the mean of group A from each of the 5 heights in group A
deviationsA&lt;-heights$A-meanA; deviationsA
## [1] -2 -1  0  1  2
# Same for C: we subtract the group mean from each observation in the group
deviationsC&lt;-heights$C-meanC; deviationsC
## [1] -2  0  0  0  2
# Next, we square these differences for both groups:
sqDevsA&lt;-deviationsA^2; sqDevsA
## [1] 4 1 0 1 4
sqDevsC&lt;-deviationsC^2; sqDevsC
## [1] 4 0 0 0 4
# Then we add up all of these squared deviations
sumSqDevs&lt;-sum(sqDevsA,sqDevsC); sumSqDevs
## [1] 18
# Finally, we divide by 2(n-1) to get the pooled variance
s2p&lt;-sumSqDevs/(2*(n-1)); s2p
## [1] 2.25</code></pre>
<p>Thus, our t-statistic and our test (null hypothesis: <span class="math inline">\(\mu_A = \mu_C\)</span>, alternative: <span class="math inline">\(\mu_A \ne \mu_C\)</span>) is</p>
<pre class="r"><code>tStat&lt;-meanDiff/sqrt(s2p*(2/5))
tStat</code></pre>
<pre><code>## [1] 2.108185</code></pre>
<pre class="r"><code>1-pt(tStat,8)+pt(-tStat,8)</code></pre>
<pre><code>## [1] 0.06806525</code></pre>
<p>Thus, the probability of observing this mean difference due to chance alone is .068, and we fail to reject the null hypothesis that those two groups are different. We get the same answer by asking R to do this test for us</p>
<pre class="r"><code>t.test(heights$A,heights$C,var.equal=T)</code></pre>
<pre><code>## 
##  Two Sample t-test
## 
## data:  heights$A and heights$C
## t = 2.1082, df = 8, p-value = 0.06807
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -0.1876676  4.1876676
## sample estimates:
## mean of x mean of y 
##         8         6</code></pre>
<p>We can also quickly see that our assumption of equal variances was suitable</p>
<pre class="r"><code>t.test(heights$A,heights$C,var.equal = F)</code></pre>
<pre><code>## 
##  Welch Two Sample t-test
## 
## data:  heights$A and heights$C
## t = 2.1082, df = 7.9024, p-value = 0.06849
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -0.1923777  4.1923777
## sample estimates:
## mean of x mean of y 
##         8         6</code></pre>
<p>But the question still remains: how can we compare more than two groups simultaneously? Let’s say we just want an answer to the question of whether fertilizer condition affects plant height. How do we pose such a question? Specifically, how do we test the null hypothesis <span class="math inline">\(H_0: \mu_A=\mu_B=\mu_C=\mu_D\)</span> against the alternative hypothesis that at least one of these means does not equal the others?</p>
<div id="one-way-anova" class="section level3">
<h3>One-Way ANOVA</h3>
<p>By way of a broad overview, the approach we will take to this problem is to <em>partition</em> the total variability into two parts: one attributable to random variability within each group/condition/treatment, and one attributable to the variability between the groups themselves. The ANOVA compares the ratio of the variability between groups to the variability within the groups—if the variability <em>between</em> groups is larger than the random variability <em>within</em> groups, then the grouping variable is said to have a significant effect on the dependent variable. Put another way, if most of the total variability (e.g., in plant height) is due to the different groups, then the grouping factor (e.g., fertilizer) is affecting the outcome more at a greater-than-chance level.</p>
<p>Let’s adopt some useful notation (for observations, grand mean, group means, etc) before we return to our plant-growth scenario.</p>
<p>For subjects (individuals, plants, students, “units”), we use the subscript <span class="math inline">\(i; \ (i=1,2,3,...,i,...,n_k)\)</span> where <span class="math inline">\(n_k\)</span> is the total number of observations in a given group <span class="math inline">\(k\)</span>.<br />
For groups (conditions, treatments, etc.), we therefore use the subscript <span class="math inline">\(k; \ (k=1,2,3,...,k,...,K)\)</span> where <span class="math inline">\(K\)</span> is the total number of groups.</p>
<blockquote>
<p><span class="math inline">\(x_{ik}\)</span> : score for subject <em>i</em> in group <em>k</em><br />
<span class="math inline">\(\bar{x}_{\bullet k}\)</span> : mean of group <em>k</em><br />
<span class="math inline">\(\bar{x}_{\bullet \bullet}\)</span>: total (or “grand”) mean</p>
</blockquote>
Just to be clear—because notation is super important!
<center>
<table>
<thead>
<tr class="header">
<th align="left"></th>
<th align="center">A (<span class="math inline">\(k=1\)</span>)</th>
<th align="center">B (<span class="math inline">\(k=2\)</span>)</th>
<th align="center">C (<span class="math inline">\(k=3\)</span>)</th>
<th align="center">D (<span class="math inline">\(k=4\)</span>)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><span class="math inline">\(i=1\)</span></td>
<td align="center"><span class="math inline">\(x_{1,1}=6\)</span></td>
<td align="center"><span class="math inline">\(x_{1,2}=9\)</span></td>
<td align="center"><span class="math inline">\(x_{1,3}=4\)</span></td>
<td align="center"><span class="math inline">\(x_{1,4}=7\)</span></td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(i=2\)</span></td>
<td align="center"><span class="math inline">\(x_{2,1}=7\)</span></td>
<td align="center"><span class="math inline">\(x_{2,2}=10\)</span></td>
<td align="center"><span class="math inline">\(x_{2,3}=6\)</span></td>
<td align="center"><span class="math inline">\(x_{2,4}=9\)</span></td>
</tr>
<tr class="odd">
<td align="left"><span class="math inline">\(i=3\)</span></td>
<td align="center"><span class="math inline">\(x_{3,1}=8\)</span></td>
<td align="center"><span class="math inline">\(x_{3,2}=12\)</span></td>
<td align="center"><span class="math inline">\(x_{3,3}=6\)</span></td>
<td align="center"><span class="math inline">\(x_{3,4}=10\)</span></td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(i=4\)</span></td>
<td align="center"><span class="math inline">\(x_{4,1}=9\)</span></td>
<td align="center"><span class="math inline">\(x_{4,2}=14\)</span></td>
<td align="center"><span class="math inline">\(x_{4,3}=6\)</span></td>
<td align="center"><span class="math inline">\(x_{4,4}=11\)</span></td>
</tr>
<tr class="odd">
<td align="left"><span class="math inline">\(i=5\)</span></td>
<td align="center"><span class="math inline">\(x_{5,1}=10\)</span></td>
<td align="center"><span class="math inline">\(x_{5,2}=15\)</span></td>
<td align="center"><span class="math inline">\(x_{5,3}=8\)</span></td>
<td align="center"><span class="math inline">\(x_{5,4}=13\)</span></td>
</tr>
</tbody>
</table>
</center>
<p>In our example data, the number of groups is <span class="math inline">\(K=4\)</span> and the number of observations in each group is the same (<span class="math inline">\(n_1=n_2=...n_K=5\)</span>). The total number of observations across groups is given by <span class="math inline">\(N=\sum_{k=1}^Kn_k=n_1+n_2+...n_K\)</span></p>
<p>#Sums of Squares</p>
<p>ANOVA works by partitioning <em>sums of squares</em> (actually, sums of square deviations of <span class="math inline">\(x_{ik}\)</span> from either the group mean <span class="math inline">\(\bar{x}_{\bullet k}\)</span> or grand mean <span class="math inline">\(\bar{x}_{\bullet \bullet}\)</span>).</p>
<p>The <strong>Total Sum of Squares (<span class="math inline">\(SS_T\)</span>)</strong> is simply the sum of the squared distance of each observation from the grand mean: <span class="math inline">\(\sum (x_{ik}-\bar{x}_{\bullet \bullet})^2\)</span>. Using our notation above, this is written
<span class="math display">\[
SS_T=\sum_{k=1}^{K}\sum_{i=1}^{n_k}(x_{ik}-\bar{x}_{\bullet \bullet})^2
\]</span>
If the double summation is uncomfortable, try reading it this way: we start with group <span class="math inline">\(k=1\)</span> and, for all <span class="math inline">\(n_k=n_1\)</span> subjects in group <span class="math inline">\(k=1\)</span> we add up their squared deviations from the grand mean; then we go group <span class="math inline">\(k=2\)</span> and do the same thing; finally, we add all of the sums of squares for the individual groups together to get the total. Thus, we can unroll the summation like so
<span class="math display">\[
SS_T=\sum_{k=1}^{K}\sum_{i=1}^{n_k}(x_{ik}-\bar{x}_{\bullet \bullet})^2=\sum_{i=1}^{n_1}(x_{i1}-\bar{x}_{\bullet \bullet})^2 + \sum_{i=1}^{n_2}(x_{i2}-\bar{x}_{\bullet \bullet})^2 + ... +\sum_{i=1}^{n_3}(x_{iK}-\bar{x}_{\bullet \bullet})^2
\]</span>
Of course, you don’t have to do it by group because addition is a commutative operation. Indeed, we could use <span class="math inline">\(N=\sum_{k=1}^Kn_k\)</span> (the total number of subjects across all groups), we could just write the expression for SS_T like this
<span class="math display">\[
SS_T=\sum_{i=1}^{N}(x_{ik}-\bar{x}_{\bullet \bullet})^2
\]</span>
However, it will be important to think in terms of individuals within groups, so we will keep the earlier equation. The <span class="math inline">\(SS_T\)</span> gives us the total squared deviations from the mean, and it may actually look familiar to you: in fact, it is the numerator of several variance calculations. For example, recall the the sample variance can be calculated by
<span class="math display">\[
s^2=\frac{\sum_{i=1}^n (x_i - \bar{x})^2}{n-1}
\]</span></p>
<p>This should hint that we will ultimately be dealing with variances …but hold that thought! Now we begin the important business of taking our <span class="math inline">\(SS_T\)</span> and spliting it into a component that represents random variability <em>within each group</em> (<span class="math inline">\(SS_W\)</span>) and a component that represents variability between the groups themselves (<span class="math inline">\(SS_B\)</span>). It will be important to notice immediately that <span class="math inline">\(SS_T=SS_B+SS_W\)</span>.</p>
<p>Let’s have a look at the <strong>Between-Groups Sum of Squares (<span class="math inline">\(SS_B\)</span>)</strong> first</p>
<p><span class="math display">\[
SS_B=\sum_{k=1}^Kn_k\times (\bar{x}_{\bullet k}-\bar{x}_{\bullet \bullet})^2
\]</span></p>
<p>The quantity <span class="math inline">\(SS_B\)</span> captures how far each group mean is from the grand mean. We take the difference between each <em>group mean</em> and the <em>overall mean</em> squared, times the number of individuals in group <span class="math inline">\(k\)</span>, <span class="math inline">\(n_k\)</span>, and we add these quantities up for all groups <span class="math inline">\(k=1,...,K\)</span>. If each group has the same number of observations <span class="math inline">\(n\)</span>, then this reduces to <span class="math inline">\(n\sum_{k=1}^K(\bar{x}_{\bullet k}-\bar{x}_{\bullet \bullet})^2\)</span>. Notice that if there are <span class="math inline">\(K\)</span> groups, there will only be <span class="math inline">\(K\)</span> deviations from the grand mean. Thus, in order to have <span class="math inline">\(N\)</span> total terms in the sum, we weight each <em>group mean</em>-<em>grand mean</em> difference by multiplying each one by the number of subjects in its group (<span class="math inline">\(n_k\)</span>).</p>
<p>For the <strong>Within-Groups Sum of Squares (<span class="math inline">\(SS_W\)</span>)</strong>, we have</p>
<p><span class="math display">\[
SS_W=\sum_{k=1}^K\sum_{i=1}^{n_k}(x_{i k}-\bar{x}_{\bullet k})^2
\]</span></p>
<p>This calculates the squared distances of each observation from its own <em>group mean</em> and adds these together across all groups. Notice that we have <span class="math inline">\(N\)</span> total terms in the sum here too.</p>
<p>##Visualizing Sums of Squares</p>
<p>These formulas may be daunting at first, and it can be very helpful to see an illustration of what each one represents. So without further ado,</p>
<p><img src="/posts/2017-08-27-basic-stats-u-need-3-anova_files/figure-html/unnamed-chunk-5-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>This plot is really important! It allows you to visualize the dispersion of the data in each of the three SS calculations. On the left, we have the Total deviations <span class="math inline">\((x_{ik}-\bar{x}_{\bullet \bullet})\)</span>: black dotted lines represent the deviations of each observation (large dots) from the grand mean (black bar); in the middle, we have Within-Group deviations <span class="math inline">\((x_{ik}-\bar{x}_{\bullet k})\)</span>: the deviations of each observation from their respective group mean (colored lines); on the right, we have Between-Group deviations <span class="math inline">\((x_{\bullet k}-\bar{x}_{\bullet \bullet})\)</span>: the deviations of each group mean from the grand mean <em>times the number of observations in each group</em>.
To calculate the Total, Within-Group, and Between-Group Sums of Squares, you simply square each of the deviations in their respective plots above and then add them up, giving you three different sums.</p>
Let’s do this and then plot our totals; here’s our data again
<center>
<table>
<thead>
<tr class="header">
<th align="center">A</th>
<th align="center">B</th>
<th align="center">C</th>
<th align="center">D</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">6</td>
<td align="center">9</td>
<td align="center">4</td>
<td align="center">7</td>
</tr>
<tr class="even">
<td align="center">7</td>
<td align="center">10</td>
<td align="center">6</td>
<td align="center">9</td>
</tr>
<tr class="odd">
<td align="center">8</td>
<td align="center">12</td>
<td align="center">6</td>
<td align="center">10</td>
</tr>
<tr class="even">
<td align="center">9</td>
<td align="center">14</td>
<td align="center">6</td>
<td align="center">11</td>
</tr>
<tr class="odd">
<td align="center">10</td>
<td align="center">15</td>
<td align="center">8</td>
<td align="center">13</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr class="header">
<th align="center"><span class="math inline">\(Mean_A\)</span></th>
<th align="center"><span class="math inline">\(Mean_B\)</span></th>
<th align="center"><span class="math inline">\(Mean_C\)</span></th>
<th align="center"><span class="math inline">\(Mean_D\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><span class="math inline">\(8\)</span></td>
<td align="center"><span class="math inline">\(12\)</span></td>
<td align="center"><span class="math inline">\(6\)</span></td>
<td align="center"><span class="math inline">\(10\)</span></td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr class="header">
<th align="center"><span class="math inline">\(Grand \ Mean\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">9</td>
</tr>
</tbody>
</table>
</center>
</div>
</div>
<div id="calculations" class="section level2 tabset">
<h2>Calculations</h2>
<p>Click the button to show the full sums-of-squares calculations</p>
<button onclick="myFunction()">
Show/Hide
</button>
<div id="myDIV" class="toshow" style="display:none">
<h3 id="total">Total</h3>
<p>We will start by calculating the Total sums of squares</p>
<p><span class="math display">\[
\begin{align}
SS_T&amp;=\sum_{k=1}^{K}\sum_{i=1}^{n_k}(x_{ik}-\bar{x}_{\bullet \bullet})^2=\sum_{k=1}^{4}\sum_{i=1}^{5}(x_{ik}-9)^2 \\
&amp;=(6-9)^2+(7-9)^2+(8-9)^2+(9-9)^2+(10-9)^2+ \ \text{(...group 1)}\\
&amp;=(9-9)^2+(10-9)^2+(12-9)^2+(14-9)^2+(15-9)^2+ \ \text{(...group 2)}\\
&amp;=(4-9)^2+(6-9)^2+(6-9)^2+(6-9)^2+(8-9)^2+ \ \text{(...group 3)}\\
&amp;=(7-9)^2+(9-9)^2+(10-9)^2+(11-9)^2+(13-9)^2+ \ \text{(...group 4)}\\
...\\
&amp;=9+4+1+0+1+ \ \text{(...group 1)}\\
&amp;=0+1+9+25+36+ \ \text{(...group 2)}\\
&amp;=25+9+9+9+1+ \ \text{(...group 3)}\\
&amp;=4+0+1+4+16+ \ \text{(...group 4)}\\
&amp;=164
\end{align}
\]</span></p>
<h3 id="within">Within</h3>
<p>Now for the Within-Group sums of squares. We need our group means for this, <span class="math inline">\(\bar{x}_{\bullet k}\)</span>. We can see from the table above that they are <span class="math inline">\(\bar{x}_{\bullet 1}=8\)</span> for group A, <span class="math inline">\(\bar{x}_{\bullet 2}=12\)</span> for group B, <span class="math inline">\(\bar{x}_{\bullet 3}=6\)</span> for group C, and <span class="math inline">\(\bar{x}_{\bullet 4}=10\)</span> for group D.</p>
<p><span class="math display">\[
\begin{align}
SS_W&amp;=\sum_{k=1}^4\sum_{i=1}^{5}(x_{i k}-\bar{x}_{\bullet k})^2 \\
&amp;= \sum_{i=1}^{5}(x_{i k}-8)^2+\sum_{i=1}^{5}(x_{i k}-12)^2+\sum_{i=1}^{5}(x_{i k}-6)^2+\sum_{i=1}^{5}(x_{i k}-10)^2 \\
...\\
&amp;=(6-8)^2+(7-8)^2+(8-8)^2+(9-8)^2+(10-8)^2+ \ \text{(...group 1)}\\
&amp;=(9-12)^2+(10-12)^2+(12-12)^2+(14-12)^2+(15-12)^2+ \ \text{(...group 2)}\\
&amp;=(4-6)^2+(6-6)^2+(6-6)^2+(6-6)^2+(8-6)^2+ \ \text{(...group 3)}\\
&amp;=(7-10)^2+(9-10)^2+(10-10)^2+(11-10)^2+(13-10)^2+ \ \text{(...group 4)}\\
...\\
&amp;=4+1+0+1+4+ \ \text{(...group 1)}\\
&amp;=9+4+0+4+9+ \ \text{(...group 2)}\\
&amp;=4+0+0+0+4+ \ \text{(...group 3)}\\
&amp;=9+1+0+1+9+ \ \text{(...group 4)}\\
&amp;=64
\end{align}
\]</span></p>
<h3 id="between">Between</h3>
<p>Since we know <span class="math inline">\(SS_T=SS_W+SS_B\)</span>, we see that <span class="math inline">\(SS_B=164-64=100\)</span>, but let’s show this quickly</p>
<p><span class="math display">\[
\begin{align}
SS_B&amp;=\sum_{k=1}^Kn_k\times (\bar{x}_{\bullet k}-\bar{x}_{\bullet \bullet})^2 = 5\sum_{k=1}^4\times (\bar{x}_{\bullet k}-9)^2 \\
&amp;=5\left((8-9)^2+(12-9)^2+(6-9)^2+(10-9)^2 \right)\\
&amp;=5\left(1+9+9+1 \right)\\
&amp;=100
\end{align}
\]</span></p>
</div>
</div>
<div id="sums-of-squares-plot" class="section level2">
<h2>Sums of Squares Plot</h2>
<p><img src="/posts/2017-08-27-basic-stats-u-need-3-anova_files/figure-html/unnamed-chunk-6-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>OK great, so we have our sums of squares: How do we perform the ANOVA with them? ANOVA uses an F-test for a ratio of two variances. Recall that we can think of our sums of squares as the numerator of a variance… what about the denominator? It will be helpful to consult a generic ANOVA output table:</p>
<p>#The ANOVA Table</p>
<table>
<colgroup>
<col width="16%" />
<col width="20%" />
<col width="20%" />
<col width="20%" />
<col width="20%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Source of Variation</th>
<th align="center">SS</th>
<th align="center">df</th>
<th align="center">MS</th>
<th align="center">F</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Between Groups</td>
<td align="center"><span class="math inline">\(SS_B=\sum_{k=1}^K n_k \times(\bar{x}_{\bullet k}-\bar{x}_{\bullet \bullet})^2\)</span></td>
<td align="center"><span class="math inline">\(K-1\)</span></td>
<td align="center"><span class="math inline">\(MS_B=\frac{SS_B}{K-1}\)</span></td>
<td align="center"><span class="math inline">\(\frac{MS_B}{MS_W}\)</span></td>
</tr>
<tr class="even">
<td align="left">Within Groups</td>
<td align="center"><span class="math inline">\(SS_W=\sum_{k=1}^K\sum_{i=1}^{n_k}(x_{i k}-\bar{x}_{\bullet k})^2\)</span></td>
<td align="center"><span class="math inline">\(N-K\)</span></td>
<td align="center"><span class="math inline">\(MS_W=\frac{SS_W}{N-K}\)</span></td>
<td align="center"></td>
</tr>
<tr class="odd">
<td align="left">Total</td>
<td align="center"><span class="math inline">\(SS_T=\sum_{k=1}^{K}\sum_{i=1}^{n_k}(x_{ik}-\bar{x}_{\bullet \bullet})^2\)</span></td>
<td align="center"><span class="math inline">\(N-1\)</span></td>
<td align="center"></td>
<td align="center"></td>
</tr>
</tbody>
</table>
<p>See those <a href="https://en.wikipedia.org/wiki/Degrees_of_freedom_(statistics)">degrees of freedom</a> (df) in the third column? You can think of those as the sample size corrected for the number of <em>necessary interrelationships</em> in the calculation. Remember how, when you calculate the sample variance <span class="math inline">\(\frac{\sum_i^n(x_i-\bar{x})^2}{n-1}\)</span>, you divide by <em>n-1</em> instead of <em>n</em>? This is because in the numerator there aren’t really <em>n</em> independent things being added up: They are constrained by the sample mean! For example, say you want the sample variance of <span class="math inline">\(x={1,2,3}\)</span>. Well, <span class="math inline">\(\bar{x}=2\)</span> so your <span class="math inline">\(s^2\)</span> numerator is <span class="math inline">\((1-2)^2+(2-2)^2+(3-2)^2\)</span>, but you also know that <span class="math inline">\(3=n\bar{x}-1-2\)</span>, so you don’t even need to use 3! You can just as easly write <span class="math inline">\((1-2)^2+(2-2)^2+\left((n\bar{x}-1-2)-2\right)^2\)</span> which becomes <span class="math inline">\((1-2)^2+(2-2)^2+\left((6-1-2)-2\right)^2\)</span>, so you don’t even need to know that <span class="math inline">\(x_3=3\)</span>.<br />
If we consider the sums of squares calculations above, we see that the total sums of squares only has one <em>necessary relationship</em> among the <span class="math inline">\(N\)</span> components: the grand mean <span class="math inline">\(\bar{X}_{\bullet \bullet}\)</span>. Thus, the denominator of this variance calculation is just like the sample variance <span class="math inline">\(N-1\)</span>. Since this isn’t a “variance” in the strict sense, we divide a sum-of-squares by its degrees-of-freedom, we refer to this quotient as the Mean Squared (MS), because it represents the “mean” of the components of the sum-of-squares.</p>
<p>Indeed, thought we don’t usually calculate it explicitly, the total Mean Squared <em>is</em> just the sample variance of the dependent variable: <span class="math inline">\(\frac{SS_T}{N-1}=\frac{164}{19}=8.6\)</span></p>
<pre class="r"><code>var(c(heights$A,heights$B,heights$C,heights$D))</code></pre>
<pre><code>## [1] 8.631579</code></pre>
<p>Another side note worth mentioning here: the Mean Square Within can also be found by taking the average of the group variances:
<span class="math display">\[
\begin{align}
MS_W&amp;=\frac{\sum_{k=1}^4\sum_{i=1}^{5}(x_{i k}-\bar{x}_{\bullet k})^2}{N-K}
= \frac{\sum_{i=1}^{5}(x_{i k}-8)^2}{16}+\frac{\sum_{i=1}^{5}(x_{i k}-12)^2}{16}+\frac{\sum_{i=1}^{5}(x_{i k}-6)^2}{16}+\frac{\sum_{i=1}^{5}(x_{i k}-10)^2}{16}\\ \\
&amp;= \frac{1}{4}\left(\frac{\sum_{i=1}^{5}(x_{i k}-8)^2}{4}+\frac{\sum_{i=1}^{5}(x_{i k}-12)^2}{4}+\frac{\sum_{i=1}^{5}(x_{i k}-6)^2}{4}+\frac{\sum_{i=1}^{5}(x_{i k}-10)^2}{4}\right)\\ \\
&amp;=\frac{1}{4}\left(s^2_A+s^2_B+s^2_C+s^2_D\right)\\
\end{align}
\]</span></p>
<pre class="r"><code>mean(c(var(heights$A),var(heights$B),var(heights$C),var(heights$D)))</code></pre>
<pre><code>## [1] 4</code></pre>
<p>##Degrees of Freedom for <span class="math inline">\(SS_W\)</span> and <span class="math inline">\(SS_B\)</span></p>
<p>The degrees of freedom for <span class="math inline">\(SS_W\)</span> is easy to remember too: just look at the components of the sum in the formula and note that the observations are constrained by the 4 group means, <span class="math inline">\(\bar{x}_{\bullet k}\)</span>. Thus, 20 observations go in, but once we know 4 of the observations in a given group, we automatically know the fifth one (because we have the group mean, and <span class="math inline">\(x_5=n_k\bar{x}_{\bullet k}-(x_1+x_2+x_3+x_4)\)</span>). Thus, the degrees of freedom is given by <span class="math inline">\(N-K = 20-4 = 16\)</span>, the total number of observations minus the total number of groups.</p>
<p>Lastly, to find the degrees of freedom for <span class="math inline">\(SS_B\)</span> we look at the components of the sum-of-squares calculation: here the unique observations are the group means themselves, and they are constrained by the grand mean, such that
<span class="math display">\[
n_5\bar{x}_{\bullet 5}=N\bar{x}_{\bullet \bullet}-(n_1\bar{x}_{\bullet 1}+n_2\bar{x}_{\bullet 2}+n_3\bar{x}_{\bullet 3}+n_4\bar{x}_{\bullet 4})
\]</span>
Thus, the degrees of freedom for <span class="math inline">\(SS_B\)</span> are found by taking the number of group means and subtracting 1 for the grand mean: <span class="math inline">\(K-1=4-1=3\)</span>.</p>
<p>##The F-Test</p>
<p>We saw above that the Mean Squares are found by dividing the Sums of Squares by their DF, <span class="math inline">\(MS=\frac{SS}{df}\)</span>. Let’s fill in the ANOVA table now with all of our calculations.</p>
<table>
<colgroup>
<col width="16%" />
<col width="20%" />
<col width="20%" />
<col width="20%" />
<col width="20%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Source</th>
<th align="center">SS</th>
<th align="center">df</th>
<th align="center">MS</th>
<th align="center">F</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Between Groups</td>
<td align="center">100</td>
<td align="center">3</td>
<td align="center"><span class="math inline">\(\frac{SS_B}{K-1}=\frac{100}{3}\)</span></td>
<td align="center"><span class="math inline">\(\frac{MS_B}{MS_W}=\frac{100}{12}=8.\bar{3}\)</span></td>
</tr>
<tr class="even">
<td align="left">Within Groups</td>
<td align="center">64</td>
<td align="center">16</td>
<td align="center"><span class="math inline">\(\frac{SS_W}{N-K}=\frac{64}{16}\)</span></td>
<td align="center"></td>
</tr>
<tr class="odd">
<td align="left">Total</td>
<td align="center">164</td>
<td align="center">19</td>
<td align="center"></td>
<td align="center"></td>
</tr>
</tbody>
</table>
<p>Our F-statistic of interest is the ratio of the between-group variability (<span class="math inline">\(MS_B\)</span>) to the within-group variability (<span class="math inline">\(MS_W\)</span>), <span class="math inline">\(F=\frac{MS_B}{MS_W}\)</span>. (Note that any Mean Square statistic follows a chi-squared distribution, so the F-distribution gives the distribution of the ratio of two chi-squared random variables.) To see if our statistic is unusually large under the null hypothesis of no group differences (that is, to see if the between-group variance is larger than expected relative to the random within-group noise), we look at the probability of observing an F-statistic at least as large as this one under the null hypothesis. Note that the F distribution depends on two parameters: the numerator degrees of freedom (<span class="math inline">\(K-1=3\)</span>) and the denominator degrees of freedom (<span class="math inline">\(N-K=16\)</span>), so our test statistic follows the distribution <span class="math inline">\(F_{(3,16)}\)</span>:</p>
<pre class="r"><code>F.stat&lt;-(100/12)
numer.df&lt;-3
denom.df&lt;-16

x1&lt;-seq(F.stat,10,len=100)
x2&lt;-seq(qf(.95,numer.df,denom.df),10,len=100)
y1&lt;-df(x1,numer.df,denom.df)
y2&lt;-df(x2,numer.df,denom.df)
{curve(df(x,numer.df,denom.df),main=&quot;&quot;,xlim=c(0,10),xlab=&quot;F&quot;)
polygon(c(x2[1],x2,x2[100]),c(0,y2,0),col=&quot;black&quot;,border=NA)
polygon(c(x1[1],x1,x1[100]),c(0,y1,0),col=&quot;grey&quot;,border=NA)
abline(v=F.stat,lty=2)}</code></pre>
<p><img src="/posts/2017-08-27-basic-stats-u-need-3-anova_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
<pre class="r"><code>#p-value
1-pf(F.stat,numer.df,denom.df)</code></pre>
<pre><code>## [1] 0.0014506</code></pre>
<p>We see in the plot above that the probability of observing an F-statistic of <span class="math inline">\(8.\bar{3}\)</span> (dotted line) or larger under the null hypothesis is very unlikely, <span class="math inline">\(p&gt;F=.001\)</span>. The area in black under the <span class="math inline">\(F_{(3,16)}\)</span> marks of 5% of the probability distribution. Anything observed F-statistic in the black region would reject the null hypothesis (that group means do no differ) at the traditional significance level <span class="math inline">\(\alpha=.05\)</span>. Another way of stating the null hypothesis is this: all groups are random samples of the same population, and thus that all treatments result in the same effect. Rejecting the null hypothesis means we have non-negligible evidence that different treatments result in different effects.</p>
<p>###Why Does This Work?</p>
<p>The expected value of the within-group variance is equal to the population variance, <span class="math inline">\(E(MS_W)=\sigma^2\)</span>. However, it can be shown that the expected value of the between-group variance is equal to the population variance <em>plus</em> an additional term representing the variabiliy of the group means around the grand mean, <span class="math inline">\(E(MS_B)=\sigma^2 + \frac{\sum_{k=1}^Kn_k (\mu_{\bullet k}-\mu_{\bullet \bullet})^2}{K-1}\)</span>. Under the null hypothesis <span class="math inline">\(\mu_1=\mu_2=...=\mu_K\)</span>, this second term will equal zero, because for all <span class="math inline">\(k\)</span>, <span class="math inline">\((\mu_{\bullet k}-\mu_{\bullet \bullet})=0\)</span>. Thus, under <span class="math inline">\(H_0\)</span>, the expected value of the F-statistic is <span class="math inline">\(E(F_{stat})=E\left(\frac{MS_B}{MS_W}\right)=\frac{\sigma^2}{\sigma^2}=1\)</span>. If our observed F-statisic is significantly larger than 1 (due to large differences between group means and thus a large <span class="math inline">\(\frac{\sum_{k=1}^Kn_k (\mu_{\bullet k}-\mu_{\bullet \bullet})^2}{K-1}\)</span> term) than we have evidence against our null hypothesis, suggesting that at least one of the group means is different from the others.</p>
<p>##Doing a One-Way ANOVA in R</p>
<p>Performing a one-way ANOVA in R is very straightforward. Notice that R gives exactly the same results as our hand calculations. Note also that “Mean Squared Residuals” (or “Mean Squared Error”, MSE) refers to the same thing as “Mean Squared Within”—it is whatever variability is left over after accounting for the effect of the groups.</p>
<pre class="r"><code>anova1&lt;-aov(Height~Group,data=dat.long)
summary(anova1)</code></pre>
<pre><code>##             Df Sum Sq Mean Sq F value  Pr(&gt;F)   
## Group        3    100   33.33   8.333 0.00145 **
## Residuals   16     64    4.00                   
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
</div>
<div id="effect-size" class="section level1">
<h1>Effect Size</h1>
<p>Effect size is just what it sounds like: a measure of the strength of an effect or treatment. These go hand-in-hand with any hypothesis test, because a hypothesis test alone tells you nothing about the size of an effect per se, but only that it is statistically significant. For example, if you have an enormous sample size, then you have very high power to detect small differences. However, these small differences may not be <em>practically significant</em>, and effect sizes are crucial for giving context to any significance test.</p>
<p>A common effect-size measure for ANOVA is the eta-squared (<span class="math inline">\(\eta^2\)</span>), which is the ratio of the <span class="math inline">\(SS_B\)</span> to the <span class="math inline">\(SS_T\)</span>, <span class="math inline">\(\eta^2=\frac{SS_B}{SS_T}\)</span>. In our example above, we have <span class="math inline">\(\eta^2=\frac{100}{164}=.61\)</span> This is a measure of the variance of the dependent variable explained by the treatment in our sample. If you are familiar with regression output, it is equivalent to the R^2.</p>
<p>Another common effect-size measure for ANOVA is cohen’s <span class="math inline">\(f^2\)</span>, which is calculating using <span class="math inline">\(\eta^2\)</span>, <span class="math inline">\(f^2=\frac{\eta^2}{1-\eta^2}\)</span>. We can see by looking that <span class="math inline">\(f^2\)</span> is the ratio of variance explained to the variance <em>not</em> explained. Here, we would have <span class="math inline">\(.61/.39=1.56\)</span>.</p>
<p>According to Cohen’s (1988) guidelines (which were meant only for the social sciences, are a bit out of date, and are certainly oversimplifications), <span class="math inline">\(f^2 \ge 0.02, f^2 \ge 0.15,\)</span> and <span class="math inline">\(f^2 \ge 0.35\)</span> represent small, medium, and large effect sizes, respectively. According to this, the effect of our treatment is huge.</p>
</div>
<div id="assumptions" class="section level1">
<h1>Assumptions</h1>
<p>It is incumbent upon any user of a hypothesis-testing procedure to check the test’s underlying assumptions if they want the conclusions they draw from it to be valid. The assumptions that must be met for an ANOVA are similar to those for a t-Test, namely independent, normality (of errors), and equal variance across groups.</p>
<div id="independence" class="section level3">
<h3>Independence</h3>
<p>This one is pretty easy: a given observation should have no influence on any of the others. There are plenty of situations when this simplifying assumption doesn’t hold (imagine if you measure the same person twice!) and we will deal with these situations in the next post. For now, one plant’s height should give you no information about another plant’s height beyond knowing what fertilizer treatment they were exposed to. We achieved this by randomizing which plants got which treatment: thus, on average, the only thing different about each group should be their treatment exposure.</p>
</div>
<div id="normality-of-errors" class="section level3">
<h3>Normality (of Errors)</h3>
<p>One easy way to check normality is to look at the distribution of data in each group: if these distributions are normal, then the errors (or residuals) will be normal. Fine, but what’s a residual? We will show in the next post that ANOVA is a special case of regression, in which the concept of residuals plays a crucial role. ANOVA analyses tend to gloss over residuals, but let’s take a minute to compute them.</p>
<p>A residual is what’s left over after we account for the effect of our independent variables. In our example, once we account for the fertilizer treatment group mean <span class="math inline">\(\bar{x}_{\bullet k}\)</span>, the residual is what’s left over. ANOVA assumes that these Within-Group deviations <span class="math inline">\((x_{ik}-\bar{x}_{\bullet k})\)</span> are normally distributed. Here’s our data again:</p>
<center>
<table>
<thead>
<tr class="header">
<th align="center">A</th>
<th align="center">B</th>
<th align="center">C</th>
<th align="center">D</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">6</td>
<td align="center">9</td>
<td align="center">4</td>
<td align="center">7</td>
</tr>
<tr class="even">
<td align="center">7</td>
<td align="center">10</td>
<td align="center">6</td>
<td align="center">9</td>
</tr>
<tr class="odd">
<td align="center">8</td>
<td align="center">12</td>
<td align="center">6</td>
<td align="center">10</td>
</tr>
<tr class="even">
<td align="center">9</td>
<td align="center">14</td>
<td align="center">6</td>
<td align="center">11</td>
</tr>
<tr class="odd">
<td align="center">10</td>
<td align="center">15</td>
<td align="center">8</td>
<td align="center">13</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr class="header">
<th align="center"><span class="math inline">\(Mean_A\)</span></th>
<th align="center"><span class="math inline">\(Mean_B\)</span></th>
<th align="center"><span class="math inline">\(Mean_C\)</span></th>
<th align="center"><span class="math inline">\(Mean_D\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><span class="math inline">\(8\)</span></td>
<td align="center"><span class="math inline">\(12\)</span></td>
<td align="center"><span class="math inline">\(6\)</span></td>
<td align="center"><span class="math inline">\(10\)</span></td>
</tr>
</tbody>
</table>
</center>
<p>So, going down columns, our residuals <span class="math inline">\((x_{ik}-\bar{x}_{\bullet k})\)</span> are <span class="math inline">\((6-8),(7-8),(8-8),...,(10-10),(11-10),(13-10)\)</span>.</p>
<p>We can get these straight from our ANOVA object in R; typically, they are examined using a quantile-quantile plot (theoretical vs. observed data quantiles should be similar) or tested formally with the Shapiro-Wilk test (which tends to be overly harsh).</p>
<pre class="r"><code>round(anova1$residuals,4)</code></pre>
<pre><code>##  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 
## -2 -1  0  1  2 -3 -2  0  2  3 -2  0  0  0  2 -3 -1  0  1  3</code></pre>
<pre class="r"><code>{qqnorm(anova1$residuals); qqline(anova1$residuals)}</code></pre>
<p><img src="/posts/2017-08-27-basic-stats-u-need-3-anova_files/figure-html/unnamed-chunk-11-1.png" width="288" style="display: block; margin: auto;" /></p>
<pre class="r"><code>shapiro.test(anova1$residuals)</code></pre>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  anova1$residuals
## W = 0.94361, p-value = 0.2804</code></pre>
<p>In the S-W test, the null hypothesis is that the data are normally distributed: here, we fail to reject that null hypothesis, confirming what we see in our Q-Q plot (the quantiles of a normal distribution look similar to the quantiles of our observed data).</p>
</div>
<div id="equal-variance-homoskedasticity" class="section level3">
<h3>Equal Variance (Homoskedasticity)</h3>
<p>Fortunately, ANOVA is very robust to non-normality (provided the groups are roughly symmetrical and, if skewed, skewed the same way) and relatively robust to unequal variances (provided the sample size in each group is about the same). Looking at our box plots, we see that the spreads look a little different across the four groups. However, two standard procedures for testing the null hypothesis that group variances are equal (Bartlett’s test and Levene’s test) both fail to reject this assumption.</p>
<pre class="r"><code>library(car)</code></pre>
<pre><code>## Loading required package: carData</code></pre>
<pre class="r"><code>boxplot(dat.long$Height~dat.long$Group)</code></pre>
<p><img src="/posts/2017-08-27-basic-stats-u-need-3-anova_files/figure-html/unnamed-chunk-12-1.png" width="480" style="display: block; margin: auto;" /></p>
<pre class="r"><code>bartlett.test(dat.long$Height~dat.long$Group)</code></pre>
<pre><code>## 
##  Bartlett test of homogeneity of variances
## 
## data:  dat.long$Height by dat.long$Group
## Bartlett&#39;s K-squared = 1.6465, df = 3, p-value = 0.6489</code></pre>
<pre class="r"><code>leveneTest(dat.long$Height~dat.long$Group)</code></pre>
<pre><code>## Levene&#39;s Test for Homogeneity of Variance (center = median)
##       Df F value Pr(&gt;F)
## group  3  1.0256 0.4075
##       16</code></pre>
</div>
</div>
<div id="post-hoc-tests" class="section level1">
<h1>Post Hoc Tests</h1>
<p>After performing an ANOVA which as revealed a significant effect for a factor, we know that not all groups are the same in terms of there score on the outcome variable, but we know little else. Therefore, it is often of interest to conduct a few more tests to see which groups (levels of the factor) are actually different from one another. The most common approach is to conduct t-tests between each possible pair of groups while correcting for multiple comparisons. In our example, we have 4 means (A, B, C, D), and so we have <span class="math inline">\(4 \choose{2}\)</span> <span class="math inline">\(=\frac{4!}{2!2!}=6\)</span> unique group comparisons <span class="math inline">\(\{AB, AC, AD, BC, BD, CD\}\)</span>. Unfortunately, the more hypotheses we test, the more likely we are to get a significant difference due to chance alone. To see this, note that when we say <span class="math inline">\(\alpha=.05\)</span> for a given test, it means that it has a probability of 5% that a “significant” difference is due to chance alone. If we were to conduct 6 such tests (e.g., t-tests), the probability of making a Type I error (incorrectly rejecting <span class="math inline">\(H_0\)</span>) <em>for at least 1 of these comparisons</em> is much greater than <span class="math inline">\(\alpha=.05\)</span>, it’s <span class="math inline">\(\alpha_{familywise}=1-(1-\alpha)^6=1-.95^6=1-.735=.265\)</span>. Thus, the probability of observing a significant difference in one of the 6 comparisons—the overall probability of making at least false rejection of H_0—is actually 26.5%! When we do multiple significance tests, we want to set the familywise (or overall) error rate at 5% instead, and there are many techniques for doing so.</p>
<p>###Tukey’s Test</p>
<p>One way around this is to use an approach variously refered to as Tukey’s test, Tukey’s HSD (honestly significant difference), Tukey’s paired comparisons, etc.</p>
<p>For example, to test whether Group A and Group B differed in Height, we would calculate <em>q</em>
<span class="math display">\[
q=\frac{|\bar{x}_A-\bar{x}_B|}{\sqrt{MS_W/n}}=\frac{|8-14|}{\sqrt{4/5}}=2\sqrt5=4.472
\]</span>
We look this value up in table for the <em>studentized-range distribution</em> to find the p-value (or probability of observing a statistic at least as extreme under the null hypothesis), which can be found in R by <code>ptukey(q,nmeans=K,df=N-K,lower.tail=F)</code></p>
<pre class="r"><code>ptukey(4.472,nmeans=4,df=16,lower.tail=F)</code></pre>
<pre><code>## [1] 0.02779534</code></pre>
<p>We can easily get this for all pairwise comparisons with the <code>TukeyHSD()</code> function, which takes ANOVA-type model as its argument:</p>
<pre class="r"><code>TukeyHSD(anova1)</code></pre>
<pre><code>##   Tukey multiple comparisons of means
##     95% family-wise confidence level
## 
## Fit: aov(formula = Height ~ Group, data = dat.long)
## 
## $Group
##     diff        lwr       upr     p adj
## B-A    4  0.3810644  7.618936 0.0277901
## C-A   -2 -5.6189356  1.618936 0.4161607
## D-A    2 -1.6189356  5.618936 0.4161607
## C-B   -6 -9.6189356 -2.381064 0.0011369
## D-B   -2 -5.6189356  1.618936 0.4161607
## D-C    4  0.3810644  7.618936 0.0277901</code></pre>
<p>Thus, we see that groups A and B are significantly different, C and B are significantly different, and D and C are significantly different while holding the familywise error rate for all six comparisons at <span class="math inline">\(\alpha_{fw}=.05\)</span>, because unlike t-tests, the Tukey test applies simultaneously to all pairwise comparisons.</p>
<p>If you find yourself with unequal sample sizes across groups, you simply use the harmonic mean of the group sizes <span class="math inline">\(n_k\)</span>, <span class="math inline">\(\frac{K}{\sum_{k=1}^K \frac{1}{n_k}}=\frac{K}{\frac{1}{n_1}+\frac{1}{n_2}+...\frac{1}{n_K}}\)</span>, instead of <span class="math inline">\(n\)</span> in your calculation of <em>q</em>.</p>
<div id="bonferroni-t-tests" class="section level3">
<h3>Bonferroni T-Tests</h3>
<p>Another approach is to say OK, we are doing 6 tests, so lets set the familywise error rate to <span class="math inline">\(\alpha_{fw}=\frac{\alpha}{5}=\frac{.05}{6}=.008\bar{3}\)</span>. Thus, for any one of our paired comparisons to be different, we would need to observe a <span class="math inline">\(p&lt;.008\bar{3}\)</span>. This method is much more conservative (that is, it tends to over-correct, making it more likely that we make a Type II error by failing to reject a false <span class="math inline">\(H_0\)</span>). We can see this by running all 6 t-tests like so:</p>
<pre class="r"><code># A vs. B
t.test(dat.long[dat.long$Group==&#39;A&#39;,]$Height,dat.long[dat.long$Group==&#39;B&#39;,]$Height,var.equal = T)$p.value
## [1] 0.01756221
#
# A vs. C
t.test(dat.long[dat.long$Group==&#39;A&#39;,]$Height,dat.long[dat.long$Group==&#39;C&#39;,]$Height,var.equal = T)$p.value
## [1] 0.06806525
#
# A vs. D
t.test(dat.long[dat.long$Group==&#39;A&#39;,]$Height,dat.long[dat.long$Group==&#39;D&#39;,]$Height,var.equal = T)$p.value
## [1] 0.1411133
#
# B vs. C
t.test(dat.long[dat.long$Group==&#39;B&#39;,]$Height,dat.long[dat.long$Group==&#39;C&#39;,]$Height,var.equal = T)$p.value
## [1] 0.00175135
#
# B vs. D
t.test(dat.long[dat.long$Group==&#39;B&#39;,]$Height,dat.long[dat.long$Group==&#39;D&#39;,]$Height,var.equal = T)$p.value
## [1] 0.2237477
#
# C vs. D
t.test(dat.long[dat.long$Group==&#39;C&#39;,]$Height,dat.long[dat.long$Group==&#39;D&#39;,]$Height,var.equal = T)$p.value
## [1] 0.009632847</code></pre>
<p>Notice here that only <em>B vs. C</em> is found to be significantly different at <span class="math inline">\(\alpha=.008\bar{3}\)</span> whereas using Tukey’s test, <em>A vs. B</em> and <em>C vs. D</em> were significant as well.</p>
</div>
<div id="stepdown-bonferroni-holm" class="section level3">
<h3>Stepdown: Bonferroni-Holm</h3>
<p>We will look at one last correction that is a less conservative variation on bonferroni. Here, we run our six t-tests like we did above, and we sort our p-values from least to greatest:</p>
<pre class="r"><code>bf_holm&lt;-data.frame(Comparison=c(&quot;AB&quot;,&quot;AC&quot;,&quot;AD&quot;,&quot;BC&quot;,&quot;BD&quot;,&quot;CD&quot;),Pvalue=c(
t.test(dat.long[dat.long$Group==&#39;A&#39;,]$Height,dat.long[dat.long$Group==&#39;B&#39;,]$Height,var.equal = T)$p.value,
t.test(dat.long[dat.long$Group==&#39;A&#39;,]$Height,dat.long[dat.long$Group==&#39;C&#39;,]$Height,var.equal = T)$p.value,
t.test(dat.long[dat.long$Group==&#39;A&#39;,]$Height,dat.long[dat.long$Group==&#39;D&#39;,]$Height,var.equal = T)$p.value,
t.test(dat.long[dat.long$Group==&#39;B&#39;,]$Height,dat.long[dat.long$Group==&#39;C&#39;,]$Height,var.equal = T)$p.value,
t.test(dat.long[dat.long$Group==&#39;B&#39;,]$Height,dat.long[dat.long$Group==&#39;D&#39;,]$Height,var.equal = T)$p.value,
t.test(dat.long[dat.long$Group==&#39;C&#39;,]$Height,dat.long[dat.long$Group==&#39;D&#39;,]$Height,var.equal = T)$p.value))

bf_holm[order(bf_holm$Pvalue),]</code></pre>
<pre><code>##   Comparison      Pvalue
## 4         BC 0.001751350
## 6         CD 0.009632847
## 1         AB 0.017562209
## 2         AC 0.068065248
## 3         AD 0.141113281
## 5         BD 0.223747695</code></pre>
<p>Now then, the Bonferroni-Holm procedure is as follows</p>
<ul>
<li>Rank comparisons from smallest p-value to largest (<span class="math inline">\(c=1,2,...N_c\)</span>)</li>
<li>Start with the comparison with the smallest p-value (i.e., <span class="math inline">\(c=1\)</span>)</li>
<li>Set the <span class="math inline">\(\alpha_c\)</span> for each comparison <span class="math inline">\(c\)</span> at <span class="math inline">\(\frac{.05}{(N_c+1)-c}\)</span>.</li>
<li>If <span class="math inline">\(p_1 \le \alpha_1\)</span>, move on to <span class="math inline">\(c=2\)</span></li>
<li>STOP when <span class="math inline">\(p_c \not\le \alpha_c\)</span> (no more tests)</li>
</ul>
<p>For example, our smallest p-value is <span class="math inline">\(BC\)</span> and we have <span class="math inline">\(\alpha_1=\frac{.05}{(6+1)-1}=\frac{.05}{6}=.008\bar{3}\)</span>. So for the first comparison, the p-value is the same as Bonferroni. Since <span class="math inline">\(.00175 \le .008\bar{3}\)</span>, we say that groups <span class="math inline">\(B\)</span> and <span class="math inline">\(C\)</span> are significantly different, and we move on to our the comparison with the second-smallest p-value, <span class="math inline">\(CD\)</span>. Here we get <span class="math inline">\(\alpha_2=\frac{.05}{(6+1)-2}=\frac{.05}{5}=.01\)</span>, and since <span class="math inline">\(p_2=.00963&lt;.01\)</span>, groups <span class="math inline">\(C\)</span> and <span class="math inline">\(D\)</span> are significantly different. For the comparison with the third-smallest p-value, <span class="math inline">\(AB\)</span>, we have <span class="math inline">\(\alpha_3=\frac{.05}{(6+1)-3}=\frac{.05}{4}=.0125\)</span>, but since <span class="math inline">\(p_3=.0176 \not\le .0125\)</span>, groups <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are not significantly different, and we stop.</p>
<p>Notice that using this procedure, 2 comparisons were found to be significantly different (compared to 1 using Bonferonni and 3 using Tukey).</p>
<p>Also note that the Bonferonni and Bonferroni-Holm procedures and general and can be used for any set of hypothesis tests that one is conducting.</p>
<p>####End</p>
<p>I hope you have enjoyed this introduction to ANOVA! I wanted to talk about power analysis but I think I had better save this topic for the next ANOVA post, where we deal with multifactor designs like the two-way ANOVA and where we discuss interactions. Stay tuned!</p>
<p>####Postscript (What to do if your ANOVA assumptions are violated)</p>
<p>If your assumptions are violated (e.g, if your samples are too small to assess normality), you can use the non-parametric Kruskal Wallis test. It tests whether the distribution of your response variable is the same across groups: if the distributions are similar, you can interpret it as testing whether there is a difference in medians between groups.</p>
<pre class="r"><code>kruskal.test(Height~Group,data=dat.long)</code></pre>
<pre><code>## 
##  Kruskal-Wallis rank sum test
## 
## data:  Height by Group
## Kruskal-Wallis chi-squared = 12.291, df = 3, p-value = 0.006451</code></pre>
<script>
function myFunction() {
    var x = document.getElementById('myDIV');
    if (x.style.display === 'none') {
        x.style.display = 'block';
    } else {
        x.style.display = 'none';
    }
}
</script>
</div>
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>Thanks Dr. Emmer, Professor Emeritus at UT Austin, In whose last-class-ever I learned so much!<a href="#fnref1" class="footnote-back">↩</a></p></li>
</ol>
</div>

  </div>
  


<div class="navigation navigation-single">
    
    <a href="/posts/basic-stats-u-need-t-test/" class="navigation-prev">
      <i aria-hidden="true" class="fa fa-chevron-left"></i>
      <span class="navigation-tittle">Basic Stats U Need #2: T-Test</span>
    </a>
    
    
    <a href="/posts/statistical-validity/" class="navigation-next">
      <span class="navigation-title">Validity in Research</span>
      <i aria-hidden="true" class="fa fa-chevron-right"></i>
    </a>
    
</div>


  

  
    


</article>


        </div>
        
    

<script defer src="https://use.fontawesome.com/releases/v5.5.0/js/all.js" integrity="sha384-GqVMZRt5Gn7tB9D9q7ONtcp4gtHIUEW/yG7h98J7IpE3kpi+srfFyyB/04OV6pG0" crossorigin="anonymous"></script>


    
    
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.13.1/highlight.min.js"></script>
        
    
    <script type="text/javascript">
        
        hljs.initHighlightingOnLoad();
    </script>
    




    



    </body>
</html>
